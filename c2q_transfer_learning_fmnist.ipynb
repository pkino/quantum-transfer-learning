{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Hybrid transfer learning for image classification (CIFAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a hybrid network for image classification, developed according to the *classical-to-quantum transfer learning* scheme presented in [1].\n",
    "\n",
    "This notebook is inspired by the official PyTorch  [tutorial on transfer learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) by Sasank Chilamkurthy [2].\n",
    "\n",
    "The starting point is a convolutional neural network—ResNet18, introduced by Microsoft in 2016 [3]—which is pre-trained on the public ImageNet dataset. We replace the last fully connected layer with a *dressed quantum circuit* [1] that we train on a different dataset. \n",
    "\n",
    "Specifically, we focus on the following sub-classes of the CIFAR 10 dataset:\n",
    "- Ref. [1], Example 3, dataset (a): *dogs* and *cats*.\n",
    "- Ref. [1], Example 3, dataset (b): *planes* and *cars*.\n",
    "\n",
    "The code can be easily modified to deal with different and/or more CIFAR classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General setup\n",
    "**Important:** this code makes use of the machine learning framework *PyTorch*, which is assumed to be correctly installed.\n",
    "\n",
    "The main imported modules are: some common PyTorch libraries, the quantum \n",
    "software framework `pennylane` [4] and the python plotting library `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "# OpenMP: number of parallel threads.\n",
    "%env OMP_NUM_THREADS=1\n",
    "\n",
    "# Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# Pennylane\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "# Other tools\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please choose and run only one of the following two cells, depending on the dataset of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings to reproduce the results of ***Ref. [1], Example 3, dataset (a)***, i.e., _dogs_ vs. _cats_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_classes = ['cat', 'dog']  # Subset of CIFAR ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "n_qubits = 4                       # Number of qubits\n",
    "quantum = True                     # If set to \"False\", the dressed quantum circuit is replaced by \n",
    "                                   # An enterily classical net (defined by the next parameter). \n",
    "classical_model = '512_n'          # Possible choices: '512_n','512_nq_n','551_512_n'. [nq=n_qubits, n=num_filtered_classes]\n",
    "step = 0.001                       # Learning rate\n",
    "batch_size = 8                     # Number of samples for each training step\n",
    "num_epochs = 3                     # Number of training epochs\n",
    "q_depth = 5                        # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 1             # Learning rate reduction applied every 10 epochs.                       \n",
    "max_layers = 15                    # Keep 15 even if not all are used.\n",
    "q_delta = 0.01                     # Initial spread of random quantum weights\n",
    "rng_seed = 0                       # Seed for random number generator\n",
    "start_time = time.time()           # start of the computation timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings to reproduce the results of ***Ref. [1], Example 3, dataset (b)***, i.e., _planes_ vs. _cars_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_classes = ['plane', 'car'] # Subset of CIFAR ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "n_qubits = 4                        # Number of qubits\n",
    "quantum = True                      # If set to \"False\", the dressed quantum circuit is replaced by \n",
    "                                    # An enterily classical net (defined by the next parameter). \n",
    "classical_model = '512_n'           # Possible choices: '512_n','512_nq_n','551_512_n'. [nq=n_qubits, n=num_filtered_classes]\n",
    "step = 0.0007                       # Learning rate\n",
    "batch_size = 8                      # Number of samples for each training step\n",
    "num_epochs = 3                      # Number of training epochs\n",
    "q_depth = 4                         # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1            # Learning rate reduction applied every 3 epochs.                       \n",
    "max_layers = 15                     # Keep 15 even if not all are used.\n",
    "q_delta = 0.01                      # Initial spread of random quantum weights\n",
    "rng_seed = 0                        # Seed for random number generator\n",
    "start_time = time.time()            # Start of the computation timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_classes = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck'] # Subset of CIFAR ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "n_qubits = 20                       # Number of qubits\n",
    "quantum = True                      # If set to \"False\", the dressed quantum circuit is replaced by \n",
    "                                    # An enterily classical net (defined by the next parameter). \n",
    "classical_model = '512_n'           # Possible choices: '512_n','512_nq_n','551_512_n'. [nq=n_qubits, n=num_filtered_classes]\n",
    "step = 0.0007                       # Learning rate\n",
    "batch_size = 8                      # Number of samples for each training step\n",
    "num_epochs = 3                      # Number of training epochs\n",
    "q_depth = 4                         # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1            # Learning rate reduction applied every 3 epochs.                       \n",
    "max_layers = 15                     # Keep 15 even if not all are used.\n",
    "q_delta = 0.01                      # Initial spread of random quantum weights\n",
    "rng_seed = 0                        # Seed for random number generator\n",
    "start_time = time.time()            # Start of the computation timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] # Subset of CIFAR ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "n_qubits = 8                       # Number of qubis\n",
    "quantum = True                      # If set to \"False\", the dressed quantum circuit is replaced by \n",
    "                                    # An enterily classical net (defined by the next parameter). \n",
    "classical_model = '512_n'           # Possible choices: '512_n','512_nq_n','551_512_n'. [nq=n_qubits, n=num_filtered_classes]\n",
    "step = 0.0007                       # Learning rate\n",
    "batch_size = 8                      # Number of samples for each training step\n",
    "num_epochs = 5                      # Number of training epochs\n",
    "q_depth = 4                         # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1            # Learning rate reduction applied every 3 epochs.                       \n",
    "max_layers = 15                     # Keep 15 even if not all are used.\n",
    "q_delta = 0.01                      # Initial spread of random quantum weights\n",
    "rng_seed = 0                        # Seed for random number generator\n",
    "start_time = time.time()            # Start of the computation timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us initialize a PennyLane with the default simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=n_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure PyTorch to use CUDA, only if available. Otherwise simply use the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading\n",
    "\n",
    "**Remark:** It may take several minutes to download the CIFAR dataset (only the first time).\n",
    "The PyTorch packages `torchvision` and `torch.utils.data` are used for loading the dataset and performing standard preliminary image operations: resize, center, crop, normalize, *etc.* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fshion MNIST\n",
    "# Fixed pre-processing operations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(224),     # uncomment for data augmentation\n",
    "        #transforms.RandomHorizontalFlip(),     # uncomment for data augmentation\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize input channels using mean values and standard deviations of ImageNet.\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =================== begin CIFAR dataset loading ===================\n",
    "trainset_full = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=data_transforms['train'])\n",
    "testset_full = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=data_transforms['val'])\n",
    "image_datasets_full={'train': trainset_full, 'val': testset_full}\n",
    "\n",
    "# CIFAR classes\n",
    "class_names = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "# Get indices of samples associated to filtered_classes\n",
    "filtered_labels=[class_names.index(cl) for cl in filtered_classes]\n",
    "sub_indices={'train': [], 'val': []}\n",
    "for phase in ['train', 'val']:\n",
    "    for idx, label in enumerate(image_datasets_full[phase].targets):  \n",
    "        if label in filtered_labels:\n",
    "            sub_indices[phase].append(idx)\n",
    "            \n",
    "# Initialize sub-datasets according to filtered indices\n",
    "image_datasets = {x: torch.utils.data.Subset(image_datasets_full[x], sub_indices[x])\n",
    "                for x in ['train', 'val']}\n",
    "\n",
    "def labels_to_filtered(labels):\n",
    "    \"\"\"Maps CIFAR labels (0,1,2,3,4,5,6,7,8,9) to the index of filtered_labels\"\"\"\n",
    "    return [filtered_labels.index(label) for label in labels]\n",
    "# =================== end CIFAR dataset loading ==========================\n",
    "\n",
    "# Number of samples\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "# Initialize dataloader\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                  batch_size=batch_size, shuffle=True, num_workers=0) for x in ['train', 'val']}\n",
    "\n",
    "# Function to plot images from tensors\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # We apply the inverse of the initial normalization operation.\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show a batch of the test data, just to have an idea of the classification problem.<br>\n",
    "*Hint:* re-run the next cell to see more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['val']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get reproducible results, we set a manual seed for the random number generator and re-initialize the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(rng_seed)\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                  batch_size=batch_size, shuffle=True, num_workers=0) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid transfer learning model (classical-to-quantum).\n",
    "\n",
    "We first define some quantum layers that will compose the quantum circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_layer(nqubits):\n",
    "    \"\"\"Layer of single-qubit Hadamard gates. \n",
    "    \"\"\"\n",
    "    for idx in range(nqubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "        \n",
    "def RY_layer(w):\n",
    "    \"\"\"Layer of parametrized qubit rotations around the y axis. \n",
    "    \"\"\"\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RY(element, wires=idx)\n",
    "\n",
    "def entangling_layer(nqubits):\n",
    "    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\n",
    "    \"\"\"\n",
    "    # In other words it should apply something like :\n",
    "    # CNOT  CNOT  CNOT  CNOT...  CNOT\n",
    "    #   CNOT  CNOT  CNOT...  CNOT  \n",
    "    for i in range(0, nqubits - 1, 2): # Loop over even indices: i=0,2,...N-2  \n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1,2): # Loop over odd indices:  i=1,3,...N-3\n",
    "        qml.CNOT(wires=[i, i + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the quantum circuit by using the PennyLane `qnode` decorator . The structure is that of a typical variational quantum circuit:\n",
    "1. All qubits are first initialized in a balanced superposition of *up* and *down* states, then they are rotated according to the input parameters (local embedding);\n",
    "2. Successively a sequence of trainable rotation layers and constant entangling layers is applied. This block is responsible for the main computation necessary to solve the classification problem.\n",
    "3. Eventually, for each qubit, the local expectation value of the Z operator is measured. This produces a classical output vector, suitable for additional post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface='torch')\n",
    "def q_net(q_in, q_weights_flat):\n",
    "        \n",
    "        # Reshape weights\n",
    "        q_weights = q_weights_flat.reshape(max_layers, n_qubits)\n",
    "        \n",
    "        # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "        H_layer(n_qubits)\n",
    "        \n",
    "        # Embed features in the quantum node\n",
    "        RY_layer(q_in)\n",
    "       \n",
    "        # Sequence of trainable variational layers\n",
    "        for k in range(q_depth):\n",
    "            entangling_layer(n_qubits)\n",
    "            RY_layer(q_weights[k+1])\n",
    "\n",
    "        # Expectation values in the Z basis\n",
    "        return [qml.expval(qml.PauliZ(j)) for j in range(n_qubits)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define a custom `torch.nn.Module` representing a *dressed* quantum circuit.<br>\n",
    "This is a concatenation of:\n",
    "1. A classical pre-processing layer (`nn.Linear`)\n",
    "2. A classical activation function (`F.tanh`)\n",
    "3. A constant `np.pi/2.0` scaling factor.\n",
    "2. The previously defined quantum circuit (`q_net`)\n",
    "2. A classical post-processing layer (`nn.Linear`)\n",
    "\n",
    "The input of the module is a batch of vectors with 512 real parameters (features) and the output is a batch of vectors with *n* real outputs (one for each class of images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantumnet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.pre_net = nn.Linear(512, n_qubits)\n",
    "            self.q_params = nn.Parameter(q_delta * torch.randn(max_layers * n_qubits))\n",
    "            self.post_net = nn.Linear(n_qubits, len(filtered_classes))\n",
    "\n",
    "        def forward(self, input_features):\n",
    "            pre_out = self.pre_net(input_features) \n",
    "            q_in = torch.tanh(pre_out) * np.pi / 2.0   \n",
    "            \n",
    "            # Apply the quantum circuit to each element of the batch, and append to q_out\n",
    "            q_out = torch.Tensor(0, n_qubits)\n",
    "            q_out = q_out.to(device)\n",
    "            for elem in q_in:\n",
    "                q_out_elem = q_net(elem,self.q_params).float().unsqueeze(0)\n",
    "                q_out = torch.cat((q_out, q_out_elem))\n",
    "            return self.post_net(q_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to build our full hybrid classical-quantum network. We follow the *transfer learning* approach:\n",
    "1. First load the classical pre-trained network *ResNet18* from the `torchvision.models` zoo.<br> **Important:** the model is downloaded from Internet and it may take a long time (only the first time). \n",
    "2. Freeze all the weights since they should not be trained.\n",
    "3. Replace the last fully connected layer with our trainable dressed quantum circuit (`Quantumnet`). Alternatively, if `quantum==False`, an entirely classical analogue is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model_hybrid.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if quantum:\n",
    "    model_hybrid.fc = Quantumnet()\n",
    "\n",
    "elif classical_model == '512_n':\n",
    "    model_hybrid.fc = nn.Linear(512,len(filtered_classes))\n",
    "\n",
    "elif classical_model == '512_nq_n':\n",
    "    model_hybrid.fc = nn.Sequential(nn.Linear(512, n_qubits),torch.nn.ReLU(),nn.Linear(n_qubits, len(filtered_classes))) \n",
    "\n",
    "elif classical_model == '551_512_n':\n",
    "    model_hybrid.fc = nn.Sequential(nn.Linear(512, 512), torch.nn.ReLU(), nn.Linear(512, len(filtered_classes)))\n",
    "\n",
    "# Use CUDA or CPU according to the \"device\" object.\n",
    "model_hybrid = model_hybrid.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and results\n",
    "Before training the network we need to specify the *loss* function. We use the *relative entropy* as objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also initialize the *optimizer* which is called at each training step in order to update the weights of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_hybrid = optim.Adam(model_hybrid.fc.parameters(), lr=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We schedule to reduce the learning rate by a factor of `gamma_lr_scheduler` every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_hybrid, step_size=3, gamma=gamma_lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows is a training function that will be called later. This function should return a trained model that can be used to make predictions (classifications). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "        since = time.time()\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_acc = 0.0\n",
    "        best_loss = 10000.0   # Large arbitrary number\n",
    "        best_acc_train = 0.0\n",
    "        best_loss_train = 10000.0  # Large arbitrary number\n",
    "        print('Training started:')\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    # Set model to training mode\n",
    "                    scheduler.step()\n",
    "                    model.train() \n",
    "                else:\n",
    "                    # Set model to evaluate mode\n",
    "                    model.eval()   \n",
    "                \n",
    "                # Iteration loop\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                n_batches = dataset_sizes[phase] // batch_size\n",
    "                it = 0\n",
    "                for inputs, cifar_labels in dataloaders[phase]:\n",
    "                    since_batch = time.time()\n",
    "                    batch_size_ = len(inputs)\n",
    "                    inputs = inputs.to(device)\n",
    "                    inputs = inputs.expand(8,3,224,224)\n",
    "                    labels = torch.tensor(labels_to_filtered(cifar_labels))\n",
    "                    labels = labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # Track/compute gradient and make an optimization step only when training\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            \n",
    "                    # Print iteration results\n",
    "                    running_loss += loss.item() * batch_size_\n",
    "                    batch_corrects = torch.sum(preds == labels.data).item()\n",
    "                    running_corrects += batch_corrects\n",
    "                    print('Phase: {} Epoch: {}/{} Iter: {}/{} Batch time: {:.4f}'.format(phase, epoch + 1, num_epochs, it + 1, n_batches + 1, time.time() - since_batch), end='\\r', flush=True)\n",
    "                    it += 1\n",
    "                \n",
    "                # Print epoch results\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "                print('Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}             '.format('train' if phase == 'train' else 'val  ', epoch + 1, num_epochs, epoch_loss, epoch_acc))\n",
    "                \n",
    "                # Check if this is the best model wrt previous epochs\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                if phase == 'val' and epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                if phase == 'train' and epoch_acc > best_acc_train:\n",
    "                    best_acc_train = epoch_acc\n",
    "                if phase == 'train' and epoch_loss < best_loss_train:\n",
    "                    best_loss_train = epoch_loss\n",
    "        \n",
    "        # Print final results             \n",
    "        model.load_state_dict(best_model_wts)\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best test loss: {:.4f} | Best test accuracy: {:.4f}'.format(best_loss, best_acc))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready perform the actual training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikuhide.kinoshita/.pyenv/versions/3.7.3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: train Epoch: 1/5 Iter: 46/7501 Batch time: 5.4965\r"
     ]
    }
   ],
   "source": [
    "model_hybrid = train_model(model_hybrid, criterion, optimizer_hybrid, exp_lr_scheduler, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the optimal weights that achieved the best accuracy into a PyTorch file that will be created in the current working directory. In this way, the saved weights can be loaded in the future without training again.\n",
    "\n",
    "**Important: Be aware that running next cell will overwrite a previously saved file. So, we suggest to run the next cell only after a good training process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if quantum:\n",
    "        torch.save(model_hybrid.state_dict(), \n",
    "            'quantum_' + filtered_classes[0] + '_' + filtered_classes[1] + '.pt'\n",
    "        )\n",
    "else:\n",
    "        torch.save(model_hybrid.state_dict(), \n",
    "            'classical_' + filtered_classes[0] + '_' + filtered_classes[1] + '.pt'\n",
    "        )\n",
    "print(\"Model state_dict saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model from file\n",
    "To load the pre-trained weights it is necessary to first define the model. So, before this cell, one should have run all the cells above the *[Training and results](##Training_and_results)* section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if quantum:\n",
    "    model_hybrid.load_state_dict(torch.load(\n",
    "        'quantum_' + filtered_classes[0] + '_' + filtered_classes[1] + '.pt'\n",
    "        )\n",
    "    )\n",
    "                                 \n",
    "else:\n",
    "    model_hybrid.load_state_dict(torch.load(\n",
    "        'classical_' + filtered_classes[0] + '_' + filtered_classes[1] + '.pt'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the model to the test dataset to compute the associated *loss* and *accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "n_batches = dataset_sizes['val'] // batch_size\n",
    "it = 0\n",
    "model_hybrid.eval()\n",
    "\n",
    "# Testing loop\n",
    "for inputs, cifar_labels in dataloaders['val']:\n",
    "    inputs = inputs.to(device)\n",
    "    inputs = inputs.expand(8,3,224,224)\n",
    "    labels = torch.tensor(labels_to_filtered(cifar_labels))\n",
    "    labels = labels.to(device)\n",
    "    batch_size_ = len(inputs)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model_hybrid(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "    running_loss += loss.item() * batch_size_\n",
    "    batch_corrects = torch.sum(preds == labels.data).item()\n",
    "    running_corrects += batch_corrects\n",
    "    print('Iter: {}/{}'.format(it+1,n_batches+1), end='\\r', flush=True)\n",
    "    it += 1\n",
    "                    \n",
    "# Print final results\n",
    "epoch_loss = running_loss / dataset_sizes['val']\n",
    "epoch_acc = running_corrects / dataset_sizes['val']\n",
    "print('\\nTest Loss: {:.4f} Test Acc: {:.4f}        '.format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model\n",
    "Let us compute and the visualize the predictions for a batch of test data.\n",
    "*Hint:* re-run the next cell to see more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6, fig_name='Predictions'):\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(fig_name)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, cifar_labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            inputs = inputs.expand(8,3,224,224)\n",
    "            labels = torch.tensor(labels_to_filtered(cifar_labels))\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('[{}]'.format(filtered_classes[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "                if images_so_far == num_images:\n",
    "                    return\n",
    "        \n",
    "visualize_model(model_hybrid, num_images=4)\n",
    "print(n_qubits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Andrea Mari, Thomas R. Bromley, Josh Izaac, Maria Schuld, and Nathan Killoran. _Transfer learning in hybrid classical-quantum neural networks_. [arXiv:1912.08278](https://arxiv.org/abs/1912.08278), (2019).\n",
    "\n",
    "[2] Sasank Chilamkurthy. PyTorch transfer learning tutorial. https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html.\n",
    "\n",
    "[3] Kaiming He, Xiangyu Zhang, Shaoqing ren and Jian Sun. _Deep residual learning for image recognition_.\n",
    "  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 770-778 (2016). [DOI: 10.1109/CVPR.2016.90]( https://doi.org/10.1109/CVPR.2016.90).\n",
    "  \n",
    "[4] Ville Bergholm, Josh Izaac, Maria Schuld, Christian Gogolin, Carsten Blank, Keri McKiernan, and Nathan Killoran. PennyLane: Automatic differentiation of hybrid quantum-classical computations. [arXiv:1811.04968](https://arxiv.org/abs/1811.04968), (2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
